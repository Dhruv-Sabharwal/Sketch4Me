{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import keras\n",
    "import keras.applications\n",
    "from keras.layers import Conv2D, Dense, Flatten, BatchNormalization, Dropout, MaxPooling2D\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "import keras.layers as layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from google.colab import drive\n",
    "import skimage.transform\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "1D4vuHNf5nn6",
    "outputId": "25366b49-64ba-4603-fcaa-d8d01a5efb10"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "!git clone -l -s https://github.com/Dhruv-Sabharwal/GAN_Face_Creator data\n",
    "%cd data\n",
    "!ls\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6E64AiYV5ruC"
   },
   "outputs": [],
   "source": [
    "# We will train the CNN to classify only one attribute at once. Hence, we will have n CNN classifying models for n attributes.\n",
    "df=pd.read_csv('celeba-dataset/list_attr_celeba.csv') \n",
    "\n",
    "# We will use equal number of '+1' and '-1' images of the attribute we want to classify\n",
    "labels1=df.loc[df['Smiling']==1]\n",
    "labels1=labels1[:10000]\n",
    "labels2=df.loc[df['Smiling']==-1]\n",
    "labels2=labels2[:10000]\n",
    "data=pd.concat([labels1,labels2])\n",
    "\n",
    "# We are going to drop all columns except the attribute we want to classify\n",
    "drop_column=['5_o_Clock_Shadow','Arched_Eyebrows','Attractive','Bags_Under_Eyes','Bald','Bangs','Big_Lips','Big_Nose','High_Cheekbones','Black_Hair','Blurry','Narrow_Eyes','Bushy_Eyebrows','No_Beard','Double_Chin','Eyeglasses','Goatee','Gray_Hair','Heavy_Makeup','Receding_Hairline','Blond_Hair','Pale_Skin','Chubby','Oval_Face','Brown_Hair','Mustache','Pointy_Nose','Young','Rosy_Cheeks','Sideburns','Straight_Hair','Mouth_Slightly_Open','Wavy_Hair','Wearing_Earrings','Wearing_Hat','Wearing_Lipstick','Wearing_Necklace','Wearing_Necktie','Male']\n",
    "data= data.drop(drop_column,axis=1,inplace=False)\n",
    "\n",
    "# Shuffling data\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5DKemrEx5uEe"
   },
   "outputs": [],
   "source": [
    "labels =[] \n",
    "# Iterate over each row and read 'image_id' and corresponding attribute value into a list\n",
    "for index, rows in data.iterrows():\n",
    "  my_list =[rows.image_id, rows.Smiling] \n",
    "  labels.append(my_list) \n",
    "\n",
    "# Read images corresponding to 'image_id' into images\n",
    "import imageio\n",
    "def data_loader(data_dir):\n",
    "  images=[]\n",
    "  i_names=[]\n",
    "  for i in range(20000):\n",
    "    i_names.append(labels[i][0])\n",
    "    images.append(imageio.imread(data_dir+'/'+labels[i][0]))\n",
    "  return i_names,images\n",
    "data_directory=\"celeba-dataset/img_align_celeba/img_align_celeba\"\n",
    "i_names,images=data_loader(data_directory)\n",
    "\n",
    "#Deleting first column ('image_id')\n",
    "for x in labels:\n",
    "  del x[0]\n",
    "\n",
    "# Reshaping the images to preferred size\n",
    "reshaped_images=[]\n",
    "for i in images:\n",
    "  reshaped_images.append(skimage.transform.resize(i,(80,80), mode ='constant'))\n",
    "reshaped_images= np.array(reshaped_images)\n",
    "labels=np.asarray(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VeEkUX4x5yFm"
   },
   "outputs": [],
   "source": [
    "# Defining the CNN model\n",
    "filepath=\"/content/drive/My Drive/AML-Proj-Attributes/Smiling_Best_Weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "size_output = 1\n",
    "model = Sequential() #The Sequential model is a linear stack of layers.\n",
    "# Conv2D - Applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (9, 9), padding='same', activation='relu', input_shape=(80,80,3)))  #When using this layer as the first layer in a model, we provide the keyword argument \"input_shape\"\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25)) #To help prevent overfitting\n",
    " \n",
    "model.add(Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')) # Applies 64 convolution filters of size 3x3 each.\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25)) #To help prevent overfitting\n",
    " \n",
    "model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', activation='relu')) # Applies 128 convolution filters of size 3x3 each.\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25)) #To help prevent overfitting\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu')) # Applies 128 convolution filters of size 3x3 each.\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25)) #To help prevent overfitting\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu')) # Applies 128 convolution filters of size 3x3 each.\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25)) #To help prevent overfitting\n",
    "\n",
    "# Classifier \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))                 \n",
    "#model.add(Dense(512, activation='sigmoid'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(256, activation='sigmoid'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(size_output, activation='tanh'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dcfYaEzAap0V",
    "outputId": "cf869b0a-d194-411d-8770-a4b7ec147d75"
   },
   "outputs": [],
   "source": [
    "history=model.fit(x=reshaped_images, y=labels, batch_size=128, epochs=50, verbose=1, callbacks=callbacks_list, validation_split=0.15, shuffle=True, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ooycVb-56Sld"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"/content/drive/My Drive/AML-Proj-Attributes/Smiling_Best_Weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nl1el7Nd6MyA"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/My Drive/AML-Proj-Attributes/Smiling_Model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "NQwfdthu8-HU",
    "outputId": "7f90f65f-fe50-4b25-e701-61feee673828"
   },
   "outputs": [],
   "source": [
    "data_dir=\"celeba-dataset/img_align_celeba/img_align_celeba\"\n",
    "image_test=imageio.imread(data_dir + '/' + '062737.jpg')\n",
    "image_test = skimage.transform.resize(image_test,(80,80,3), mode ='constant')\n",
    "image_test = np.expand_dims(image_test, axis=0)\n",
    "plt.imshow(image_test[0])\n",
    "prediction=model.predict(image_test)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "singleCNN2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
